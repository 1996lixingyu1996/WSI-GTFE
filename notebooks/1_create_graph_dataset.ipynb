{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathflowai.utils import load_sql_df\n",
    "import torch\n",
    "import os \n",
    "import sys, os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "import umap, numba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.data import Data \n",
    "import numpy as np\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import os\n",
    "import argparse\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset,DataLoader\n",
    "import os,glob, pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "import fire\n",
    "import torch_geometric\n",
    "import torch\n",
    "import scipy.sparse as sps\n",
    "from torch_cluster import radius_graph\n",
    "from torch_geometric.utils import subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root=None, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = None,None#torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        pass\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = extract_graphs()\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "\n",
    "        \n",
    "def get_graph_datasets(embedding_dir,k=8,radius=0,build_connected_components=False):\n",
    "    embeddings={os.path.basename(f).split('.')[0]: torch.load(f) for f in glob.glob(\"{}/*.pkl\".format(embedding_dir))}\n",
    "    embeddings=dict(embeddings=np.vstack([embeddings[k]['embeddings'] for k in embeddings]),\n",
    "               patch_info=pd.concat([embeddings[k]['patch_info'] for k in embeddings]))\n",
    "    df=embeddings['patch_info'].iloc[:,2:].reset_index()\n",
    "    z=pd.DataFrame(embeddings['embeddings']).loc[df.index]\n",
    "    embeddings['patch_info']=df\n",
    "    le=LabelEncoder()\n",
    "    cols=df['annotation'].value_counts().index.tolist()\n",
    "    cols=np.array(cols)\n",
    "    le=le.fit(cols)\n",
    "    df['y_true']=le.transform(cols[df[cols].values.argmax(1)])\n",
    "    weights=compute_class_weight('balanced',sorted(df['y_true'].unique()),df['y_true'].values)\n",
    "\n",
    "    def get_dataset(slide,k=8,radius=0,build_connected_components=False):\n",
    "        xy=embeddings['patch_info'][embeddings['patch_info']['ID']==slide][['x','y']]\n",
    "        xy=torch.tensor(xy.values).float().cuda()\n",
    "        X=z[embeddings['patch_info']['ID'].values==slide]\n",
    "        X=torch.tensor(X.values)\n",
    "        y=torch.tensor(df.loc[embeddings['patch_info']['ID'].values==slide,'y_true'].values)\n",
    "        if not radius:\n",
    "            G=knn_graph(xy,k=k)\n",
    "        else:\n",
    "            G=radius_graph(xy, r=radius*np.sqrt(2), batch=None, loop=True)\n",
    "        G=G.detach().cpu()\n",
    "        G=torch_geometric.utils.add_remaining_self_loops(G)[0]\n",
    "        xy=xy.detach().cpu()\n",
    "        datasets=[]\n",
    "        if build_connected_components:\n",
    "            edges=G.detach().cpu().numpy().astype(int)\n",
    "            n_components,components=list(sps.csgraph.connected_components(sps.coo_matrix((np.ones_like(edges[0]),(edges[0],edges[1])))))\n",
    "            components=torch.LongTensor(components)\n",
    "            for i in range(n_components):\n",
    "                G_new=subgraph(components==i,G,relabel_nodes=True)[0]\n",
    "                xy_new=xy[components==i]\n",
    "                X_new=X[components==i]\n",
    "                y_new=y[components==i]\n",
    "                np.random.seed(42)\n",
    "                idx=np.arange(X_new.shape[0])\n",
    "                idx2=np.arange(X_new.shape[0])\n",
    "                np.random.shuffle(idx)\n",
    "                train_idx,val_idx,test_idx=torch.tensor(np.isin(idx2,idx[:int(0.8*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.8*len(idx)):int(0.9*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.9*len(idx)):]))\n",
    "                dataset=Data(x=X_new, edge_index=G_new, edge_attr=None, y=y_new, pos=xy_new)\n",
    "                dataset.train_mask=train_idx\n",
    "                dataset.val_mask=val_idx\n",
    "                dataset.test_mask=test_idx\n",
    "                datasets.append(dataset)\n",
    "            components=components.numpy()\n",
    "                \n",
    "        else:\n",
    "            components=np.ones(X.shape[0])\n",
    "            np.random.seed(42)\n",
    "            idx=np.arange(X.shape[0])\n",
    "            idx2=np.arange(X.shape[0])\n",
    "            np.random.shuffle(idx)\n",
    "            train_idx,val_idx,test_idx=torch.tensor(np.isin(idx2,idx[:int(0.8*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.8*len(idx)):int(0.9*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.9*len(idx)):]))\n",
    "            dataset=Data(x=X, edge_index=G, edge_attr=None, y=y, pos=xy)\n",
    "            dataset.train_mask=train_idx\n",
    "            dataset.val_mask=val_idx\n",
    "            dataset.test_mask=test_idx\n",
    "            datasets.append(dataset)\n",
    "        return datasets,components\n",
    "\n",
    "\n",
    "    def extract_graphs(df,k=8,radius=0,build_connected_components=False):\n",
    "        graphs=[]\n",
    "        if build_connected_components: df['component']=-1\n",
    "        for slide in df['ID'].unique():\n",
    "            if df.loc[df['ID']==slide,'y_true'].sum():\n",
    "                G,components=get_dataset(slide,k,radius,build_connected_components)\n",
    "                graphs.extend(G) \n",
    "                if build_connected_components: df.loc[df['ID']==slide,\"component\"]=components\n",
    "        return graphs,df\n",
    "    \n",
    "    graph_dataset,df=extract_graphs(df,k,radius,build_connected_components)\n",
    "    return dict(df=df,weight=weights,graph_dataset=graph_dataset)\n",
    "\n",
    "def graph_extraction(embedding_dir,save_file='graph_dataset_test.pkl',k=8,radius=0,build_connected_components=False):\n",
    "    graph_datasets=get_graph_datasets(embedding_dir,k,radius,build_connected_components)\n",
    "    pickle.dump(graph_datasets,open(save_file,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pathflowai or https://github.com/jlevy44/PathPretrain to pretrain / extract image features first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_datasets={}\n",
    "for k in ['your_data_set']:\n",
    "    embedding_dir=f\"{k}/imagenet_embeddings\"\n",
    "    out_dir=f\"{k}/graph_datasets\"\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "    graph_extraction(embedding_dir,save_file=f'{out_dir}/imagenet_graph_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

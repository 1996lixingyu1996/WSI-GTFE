{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch\n",
    "import pickle\n",
    "import os \n",
    "import sys, os\n",
    "sys.path.insert(0,os.path.abspath(\"dgm\"))\n",
    "import umap, numba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "import argparse\n",
    "from dgm.dgm import DGM\n",
    "from dgm.plotting import *\n",
    "from dgm.utils import *\n",
    "from dgm.models import GraphClassifier, DGILearner\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "import os,glob, pandas as pd\n",
    "import copy\n",
    "import torch,os\n",
    "import pickle, numpy as np\n",
    "import fire\n",
    "\n",
    "def run_dgm(graphs,i=-1,use_clusters=False,cluster=-1,predict=False,num_intervals=3,overlap=0.1,min_component_size=150,reduction_method=\"pca\",eps=0.1):\n",
    "    np.random.seed(42)\n",
    "    embed=(umap.UMAP() if reduction_method=='umap' else PCA(n_components=2)).fit_transform(graphs[i]['z'])\n",
    "    out_graph, res = DGM(num_intervals=num_intervals, overlap=overlap, eps=eps,\n",
    "                         min_component_size=min_component_size, sdgm=True).fit_transform(graphs[i][\"G\"], embed)\n",
    "    xy=graphs[i][\"xy\"]\n",
    "    y_orig=graphs[i][(\"y\" if not predict else 'y_update')] if not use_clusters else graphs[i][\"s\"]\n",
    "    y=copy.deepcopy(y_orig)\n",
    "    if use_clusters:\n",
    "        if cluster==-1:\n",
    "            y=y.argmax(1)\n",
    "        else:\n",
    "            y=y[:,cluster]\n",
    "    c=y.flatten()\n",
    "    return out_graph,res,c,xy,y_orig\n",
    "\n",
    "def get_interaction(out_graph,xy,y_orig,res,lb=None,plot=False,le=None):\n",
    "    if not isinstance(lb,type(None)):\n",
    "        y_orig=lb.transform(y_orig)\n",
    "    node_makeup={}# only if predict\n",
    "    ROIs={}\n",
    "    for node in out_graph.nodes():\n",
    "        nodes=res['mnode_to_nodes'][node]\n",
    "        ROI=np.array([xy[i] for i in nodes]) \n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.scatter(ROI[:,0],ROI[:,1],c=c[np.array(list(nodes))],s=1)\n",
    "        node_makeup[node]=y_orig[np.array(list(nodes))].mean(0)\n",
    "        ROIs[node]=(ROI,y_orig[np.array(list(nodes))].argmax(1))\n",
    "    edges = out_graph.edges()\n",
    "    edge_weight=res['edge_weight']\n",
    "    weights = np.array([edge_weight[(min(u, v), max(u, v))] for u, v in edges], dtype=np.float32)\n",
    "    edgelist=list(edges)\n",
    "    A=np.zeros((len(lb.classes_),len(lb.classes_)))\n",
    "    for i in range(len(edgelist)):\n",
    "        send=node_makeup[edgelist[i][0]]\n",
    "        receive=node_makeup[edgelist[i][1]]\n",
    "        a=np.outer(send,receive)\n",
    "        a=(a+a.T)/2.*weights[i]\n",
    "        A+=a\n",
    "    invasion_mat=pd.DataFrame(A,columns=le.inverse_transform(np.arange(len(lb.classes_))),index=le.inverse_transform(np.arange(len(lb.classes_))))\n",
    "    return invasion_mat,ROIs,node_makeup\n",
    "\n",
    "def save_interactions(cv_split=1,\n",
    "                     results_dir=\"results\",\n",
    "                     cv_splits='cv_splits/cv_splits.pkl',\n",
    "                     datasets='datasets/graph_dataset.pkl',\n",
    "                     predictions_dir=\"predictions\",\n",
    "                     interactions_with=\"cancer\"# example, feel free to edit script or set your own\n",
    "                     ):\n",
    "    datasets=pickle.load(open(datasets,'rb'))\n",
    "    graphs=torch.load(os.path.join(predictions_dir,f\"{cv_split}.predictions.pth\"))\n",
    "    cv_splits=pickle.load(open(cv_splits,'rb'))[cv_split]\n",
    "    val_idx=cv_splits['val_idx']\n",
    "    test_idx=cv_splits['test_idx']\n",
    "    test_graphs=graphs[len(val_idx):]\n",
    "    IDs=datasets['df']['ID'].unique()[np.array(cv_splits['test_idx'])]\n",
    "    cols=datasets['df']['annotation'].value_counts().index.tolist()\n",
    "    cols=np.array(cols)\n",
    "    le=LabelEncoder().fit(cols)\n",
    "    lb=LabelBinarizer().fit(np.arange(len(cols)))\n",
    "    \n",
    "    cancer_interactions=[]\n",
    "    cancer_pred=[]\n",
    "    cancer_ROIs=[]\n",
    "    dgm_res=[]\n",
    "\n",
    "    for i,ID in enumerate(IDs):\n",
    "        kwargs=dict(graphs=test_graphs,\n",
    "                    i=i,\n",
    "                    use_clusters=False,\n",
    "                    num_intervals=2,\n",
    "                    overlap=0.01,\n",
    "                    min_component_size=100,\n",
    "                    eps=0.1,\n",
    "                    predict=True,\n",
    "                    reduction_method=\"umap\")\n",
    "        out_graph,res,c,xy,y_orig=run_dgm(**kwargs)\n",
    "        dgm_res.append((ID,(out_graph,res,c,xy,y_orig)))\n",
    "        invasion_mat,ROI,node_makeup=get_interaction(out_graph,xy,y_orig,res,lb=lb,plot=False,le=le)\n",
    "        df_pred=pd.DataFrame([dict(Counter(le.inverse_transform(y_orig)))],index=['pred']).T  \n",
    "        cancer_pred.append([ID,df_pred])\n",
    "        cancer_ROIs.append([ID,ROI])\n",
    "        cancer_interactions.append([ID,invasion_mat[interactions_with]])\n",
    "\n",
    "    dgm_res=dict(dgm_res)\n",
    "    cancer_ROIs=dict(cancer_ROIs)\n",
    "    df_pred=pd.concat([pred[1] for pred in cancer_pred],axis=1).fillna(0).T\n",
    "    df_pred.index=[pred[0] for pred in cancer_pred]\n",
    "    cancer_int=pd.concat([ci[1] for ci in cancer_interactions],axis=1).fillna(0).T\n",
    "    cancer_int.index=[ci[0] for ci in cancer_interactions]\n",
    "    cancer_int.columns=np.array(['interact_'+ci for ci in list(cancer_int)])\n",
    "    X=pd.concat([df_pred,cancer_int],axis=1)\n",
    "    results=dict(dgm_res=dgm_res,\n",
    "                cancer_ROIs=cancer_ROIs,\n",
    "                X=X)\n",
    "    torch.save(results,os.path.join(results_dir,f\"design_matrix.{cv_split}.pth\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kargs=dict(cv_split=1,\n",
    "             results_dir=\"results\",\n",
    "             cv_splits='cv_splits/cv_splits.pkl',\n",
    "             datasets='datasets/graph_dataset.pkl',\n",
    "             predictions_dir=\"predictions\",\n",
    "             interactions_with=\"cancer\")\n",
    "save_interactions(**kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "# example with sample patient-level grouping and outcome label y, load your own csv with matching slide IDs \n",
    "n_samples=200\n",
    "n_cv_splits=10\n",
    "slide_names=np.arange(n_samples)\n",
    "outcome_labels_clusters=pd.DataFrame(dict(y=np.ones((n_samples,)),group=np.ones((n_samples,))),index=slide_names)\n",
    "for i in range(n_cv_splits):\n",
    "    dff=torch.load(f\"results/design_matrix.{i}.pth\")['X']\n",
    "    dff['fold']=i\n",
    "    X.append(dff)\n",
    "X=pd.concat(X)\n",
    "X['y']=outcome_labels_clusters['y']\n",
    "X['group']=outcome_labels_clusters['group']\n",
    "X.to_csv(\"design_matrix.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
